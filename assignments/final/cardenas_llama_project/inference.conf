# inference.conf - Configuration for AI wrapper

# Inference source: local or api
INFERENCE_SOURCE="local"

# Language: en (English) or ru (Russian)
LANGUAGE="en"

# Local configuration
LOCAL_MODEL_PATH="models/Qwen2.5-0.5B-Instruct-Q6_K.gguf"
LOCAL_CONTEXT_SIZE=2048
LOCAL_NG_LAYERS=0

# API configuration
API_HOST="ai-api.hurated.com"